{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem:\n",
    "\n",
    "- In out problem, need to detect the nearest pedestrian road to see if the car is violating or not \n",
    "- need to know which part is the pedestrian road and which part is the car road  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import mmcv\n",
    "import torch\n",
    "import numpy as np\n",
    "# import ffmpeg\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "repo_path = Path(\".\").absolute().parent\n",
    "\n",
    "if os.name == \"nt\":\n",
    "    data_path = Path(\"D:\\Datas\\parking_violation\")\n",
    "else:\n",
    "    data_path = repo_path.parent / \"data\" / \"parking_violation\"\n",
    "# pkg_path = repo_path.parent / \"PINet_new\"\n",
    "sys.path.append(str(repo_path))\n",
    "# sys.path.append(str(pkg_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = str(data_path / \"sample1.mp4\")\n",
    "video = mmcv.VideoReader(video_path)\n",
    "\n",
    "# obtain basic information\n",
    "print(len(video))\n",
    "print(video.width, video.height, video.resolution, video.fps)\n",
    "\n",
    "# iterate over all frames\n",
    "for frame in video:\n",
    "    print(frame.shape)\n",
    "    break\n",
    "\n",
    "# read the next frame\n",
    "img = video.read()\n",
    "\n",
    "# read a frame by index\n",
    "img = video[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmseg\n",
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette\n",
    "print(mmseg.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = repo_path.parent / \"mmsegmentation\" / \"configs\" / \"resnest\"\n",
    "checkpoint_path = repo_path.parent / \"data\" / \"mmseg\" / \"checkpoints\"\n",
    "if not checkpoint_path.exists():\n",
    "    checkpoint_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget https://download.openmmlab.com/mmsegmentation/v0.5/resnest/deeplabv3plus_s101-d8_512x1024_80k_cityscapes/deeplabv3plus_s101-d8_512x1024_80k_cityscapes_20200807_144429-1239eb43.pth -P ~/code/data/mmseg/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = str(config_path / \"deeplabv3plus_s101-d8_512x1024_80k_cityscapes.py\")\n",
    "checkpoint_file = str(checkpoint_path / \"deeplabv3plus_s101-d8_512x1024_80k_cityscapes_20200807_144429-1239eb43.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_segmentor(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import imsaver, correct_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = correct_rgb(video[100])\n",
    "img_path = \"./imgs/test_seg.png\"\n",
    "imsaver(img, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inference_segmentor(model, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(video):\n",
    "    for frame in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in video:\n",
    "    print(frame.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = str(data_path / \"sample_video1.mp4\")\n",
    "output_path = str(data_path / \"video_output.mp4\")\n",
    "clip1 = VideoFileClip(video_path)\n",
    "white_clip = clip1.fl_image(pipeline.process) \n",
    "%time white_clip.write_videofile(output_path, audio = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 12))\n",
    "axes[0].imshow(img)\n",
    "axes[1].imshow(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"D:\\Datas\\parking_violation/sample2.mp4\")\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    torch.cuda.synchronize()\n",
    "    prevTime = time.time()\n",
    "    frame = cv2.resize(frame, (512,256))/255.0\n",
    "    frame = np.rollaxis(frame, axis=2, start=0)\n",
    "    _, _, ti = test(lane_agent, np.array([frame])) \n",
    "    curTime = time.time()\n",
    "    sec = curTime - prevTime\n",
    "    fps = 1/(sec)\n",
    "    s = \"FPS : \"+ str(fps)\n",
    "    ti[0] = cv2.resize(ti[0], (1280,800))\n",
    "    cv2.putText(ti[0], s, (0, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0))\n",
    "    cv2.imshow('frame', ti[0])\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (images[0].cpu().permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "img, fp, fn = dataloader.dataset.draw_annotation(idx, img=img, pred=prediction[0])\n",
    "if self.view == 'mistakes' and fp == 0 and fn == 0:\n",
    "    continue\n",
    "cv2.imshow('pred', img)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
